import re
import pandas as pd
from nltk.corpus import opinion_lexicon
from nltk.tokenize import word_tokenize, sent_tokenize
import nltk

# Download required NLTK resources
nltk.download(['opinion_lexicon', 'punkt', 'stopwords'])

class NegativeSentimentAnalyzer:
    def __init__(self):
        self.negative_words = set(opinion_lexicon.negative())
        self.custom_negative_phrases = self._load_custom_phrases()
        self.stop_words = set(nltk.corpus.stopwords.words('english'))
        
    def _load_custom_phrases(self, phrase_file='negative_phrases.txt'):
        """Load custom negative phrases from file"""
        custom_phrases = {
            'poor service', 'not satisfied', 'never again', 
            'terrible experience', 'worst ever', 'waste of money'
        }
        try:
            with open(phrase_file, 'r') as f:
                custom_phrases.update(line.strip().lower() for line in f)
        except FileNotFoundError:
            pass
        return custom_phrases
    
    def preprocess_text(self, text):
        """Clean and normalize text while preserving negation context"""
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
        return text
    
    def _get_ngrams(self, text, n=2):
        """Generate n-grams from text"""
        tokens = word_tokenize(text)
        return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]
    
    def detect_negative_terms(self, text):
        """Identify negative words and phrases in text"""
        text = self.preprocess_text(text)
        negative_findings = set()
        
        # Check single words
        for word in word_tokenize(text):
            if word in self.negative_words:
                negative_findings.add(word)
        
        # Check custom phrases (bigrams and trigrams)
        for n in [2, 3]:
            for ngram in self._get_ngrams(text, n):
                if ngram in self.custom_negative_phrases:
                    negative_findings.add(ngram)
        
        # Check negative patterns
        negative_patterns = [
            r'\b(not|never)\s+\w+',
            r'\b(no\s+longer|at\s+all)\b',
            r'\b(awful|horrible|terrible)\b'
        ]
        
        for pattern in negative_patterns:
            matches = re.findall(pattern, text)
            negative_findings.update(matches)
        
        return list(negative_findings)
    
    def analyze_dataset(self, dataset, text_column='text'):
        """Analyze a pandas DataFrame containing text data"""
        results = []
        
        for idx, row in dataset.iterrows():
            text = row[text_column]
            negative_terms = self.detect_negative_terms(text)
            if negative_terms:
                results.append({
                    'text': text,
                    'negative_terms': negative_terms,
                    'negative_score': len(negative_terms)
                })
        
        return pd.DataFrame(results).sort_values('negative_score', ascending=False)

# Example usage
if __name__ == "__main__":
    # Sample dataset
    data = {
        'text': [
            "The service was terrible and the food was cold.",
            "I'm not satisfied with this product, it's a waste of money.",
            "This is the worst experience I've ever had!",
            "The delivery was late and the staff was rude.",
            "Absolutely wonderful experience, highly recommend!"
        ]
    }
    df = pd.DataFrame(data)
    
    # Initialize analyzer
    analyzer = NegativeSentimentAnalyzer()
    
    # Analyze dataset
    results = analyzer.analyze_dataset(df)
    
    # Display results
    print("Negative Sentiment Analysis Results:")
    print(results[['text', 'negative_terms', 'negative_score']].to_string(index=False))
