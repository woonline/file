import re
import pandas as pd
from nltk.corpus import opinion_lexicon
from nltk.tokenize import word_tokenize, sent_tokenize
import nltk

# Download required NLTK resources
nltk.download(['opinion_lexicon', 'punkt', 'stopwords'])

class NegativeSentimentAnalyzer:
    def __init__(self):
        self.negative_words = set(opinion_lexicon.negative())
        self.custom_negative_phrases = self._load_custom_phrases()
        self.stop_words = set(nltk.corpus.stopwords.words('english'))
        
    def _load_custom_phrases(self, phrase_file='negative_phrases.txt'):
        """Load custom negative phrases from file"""
        custom_phrases = {
            'poor service', 'not satisfied', 'never again', 
            'terrible experience', 'worst ever', 'waste of money'
        }
        try:
            with open(phrase_file, 'r') as f:
                custom_phrases.update(line.strip().lower() for line in f)
        except FileNotFoundError:
            pass
        return custom_phrases
    
    def preprocess_text(self, text):
        """Clean and normalize text while preserving negation context"""
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
        return text
    
    def _get_ngrams(self, text, n=2):
        """Generate n-grams from text"""
        tokens = word_tokenize(text)
        return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]
    
    def detect_negative_terms(self, text):
        """Identify negative words and phrases in text"""
        text = self.preprocess_text(text)
        negative_findings = set()
        
        # Check single words
        for word in word_tokenize(text):
            if word in self.negative_words:
                negative_findings.add(word)
        
        # Check custom phrases (bigrams and trigrams)
        for n in [2, 3]:
            for ngram in self._get_ngrams(text, n):
                if ngram in self.custom_negative_phrases:
                    negative_findings.add(ngram)
        
        # Check negative patterns
        negative_patterns = [
            r'\b(not|never)\s+\w+',
            r'\b(no\s+longer|at\s+all)\b',
            r'\b(awful|horrible|terrible)\b'
        ]
        
        for pattern in negative_patterns:
            matches = re.findall(pattern, text)
            negative_findings.update(matches)
        
        return list(negative_findings)
    
    def analyze_dataset(self, dataset, text_column='text'):
        """Analyze a pandas DataFrame containing text data"""
        results = []
        
        for idx, row in dataset.iterrows():
            text = row[text_column]
            negative_terms = self.detect_negative_terms(text)
            if negative_terms:
                results.append({
                    'text': text,
                    'negative_terms': negative_terms,
                    'negative_score': len(negative_terms)
                })
        
        return pd.DataFrame(results).sort_values('negative_score', ascending=False)

# Example usage
if __name__ == "__main__":
    # Sample dataset
    data = {
        'text': [
            "The service was terrible and the food was cold.",
            "I'm not satisfied with this product, it's a waste of money.",
            "This is the worst experience I've ever had!",
            "The delivery was late and the staff was rude.",
            "Absolutely wonderful experience, highly recommend!"
        ]
    }
    df = pd.DataFrame(data)
    
    # Initialize analyzer
    analyzer = NegativeSentimentAnalyzer()
    
    # Analyze dataset
    results = analyzer.analyze_dataset(df)
    
    # Display results
    print("Negative Sentiment Analysis Results:")
    print(results[['text', 'negative_terms', 'negative_score']].to_string(index=False))



import spacy
from nltk.tokenize import sent_tokenize
from nltk.corpus import stopwords
from nltk import download
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download required NLTK resources
download('punkt')
download('stopwords')

# Load spaCy model for advanced NLP
nlp = spacy.load("en_core_web_sm")

# Initialize VADER sentiment analyzer
sia = SentimentIntensityAnalyzer()

# Function to identify negative sentiment words and phrases dynamically
def extract_negative_sentiment(text):
    # Tokenize the text into sentences
    sentences = sent_tokenize(text)
    
    # Variables to hold results
    negative_phrases = []
    negative_words_found = []
    sentiment_scores = []  # List to hold sentiment score info
    
    # Process each sentence using VADER and spaCy
    for sentence in sentences:
        # Analyze sentiment with VADER
        sentiment_score = sia.polarity_scores(sentence)['compound']
        
        # If the sentiment score is negative, process the words
        if sentiment_score < 0:
            negative_phrases.append(sentence)
            sentiment_scores.append(sentiment_score)  # Store the sentiment score
            
            # Process the sentence using spaCy for better context
            doc = nlp(sentence)
            
            # Extract words that carry sentiment
            for token in doc:
                # Check for adjectives, adverbs, and verbs (sentiment-bearing words)
                if token.pos_ in ['ADJ', 'VERB', 'ADV'] and token.text.lower() not in stopwords.words("english"):
                    negative_words_found.append(token.text.lower())
    
    # Remove duplicates and return results
    negative_words_found = list(set(negative_words_found))
    
    return negative_phrases, negative_words_found, sentiment_scores

# Sample complaint summary note
complaint_text = """
I am extremely disappointed with the service I received. 
The product I purchased broke after just one use. 
The support team was unhelpful and rude, and I will never buy from you again. 
I expect a refund immediately.
"""

# Extract negative sentiment phrases, words, and sentiment scores
negative_sentiment_phrases, negative_words_found, sentiment_scores = extract_negative_sentiment(complaint_text)

# Output results
if negative_sentiment_phrases or negative_words_found:
    print("Negative Sentiment Phrases Found:")
    for i, phrase in enumerate(negative_sentiment_phrases):
        print(f"- {phrase}")
        print(f"  Sentiment Score (Compound): {sentiment_scores[i]:.3f}")
    
    print("\nNegative Sentiment Words Found:")
    for word in negative_words_found:
        print(f"- {word}")
else:
    print("No negative sentiment found.")




import re
import pandas as pd
from nltk.corpus import opinion_lexicon
from nltk.tokenize import word_tokenize, sent_tokenize
import nltk

# Download required NLTK resources
nltk.download(['opinion_lexicon', 'punkt', 'stopwords'])

class NegativeSentimentAnalyzer:
    def __init__(self):
        self.negative_words = set(opinion_lexicon.negative())
        self.custom_negative_phrases = self._load_custom_phrases()
        self.stop_words = set(nltk.corpus.stopwords.words('english'))
        
    def _load_custom_phrases(self, phrase_file='negative_phrases.txt'):
        """Load custom negative phrases from file"""
        custom_phrases = {
            'poor service', 'not satisfied', 'never again', 
            'terrible experience', 'worst ever', 'waste of money'
        }
        try:
            with open(phrase_file, 'r') as f:
                custom_phrases.update(line.strip().lower() for line in f)
        except FileNotFoundError:
            pass
        return custom_phrases
    
    def preprocess_text(self, text):
        """Clean and normalize text while preserving negation context"""
        text = text.lower()
        text = re.sub(r'[^\w\s]', '', text)  # Remove punctuation
        return text
    
    def _get_ngrams(self, text, n=2):
        """Generate n-grams from text"""
        tokens = word_tokenize(text)
        return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]
    
    def detect_negative_terms(self, text):
        """Identify negative words and phrases in text"""
        text = self.preprocess_text(text)
        negative_findings = set()
        
        # Check single words
        for word in word_tokenize(text):
            if word in self.negative_words:
                negative_findings.add(word)
        
        # Check custom phrases (bigrams and trigrams)
        for n in [2, 3]:
            for ngram in self._get_ngrams(text, n):
                if ngram in self.custom_negative_phrases:
                    negative_findings.add(ngram)
        
        # Check negative patterns
        negative_patterns = [
            r'\b(not|never)\s+\w+',
            r'\b(no\s+longer|at\s+all)\b',
            r'\b(awful|horrible|terrible)\b'
        ]
        
        for pattern in negative_patterns:
            matches = re.findall(pattern, text)
            negative_findings.update(matches)
        
        return list(negative_findings)
    
    def analyze_dataset(self, dataset, text_column='text'):
        """Analyze a pandas DataFrame containing text data"""
        results = []
        
        for idx, row in dataset.iterrows():
            text = row[text_column]
            negative_terms = self.detect_negative_terms(text)
            if negative_terms:
                results.append({
                    'text': text,
                    'negative_terms': negative_terms,
                    'negative_score': len(negative_terms)
                })
        
        return pd.DataFrame(results).sort_values('negative_score', ascending=False)

# Example usage
if __name__ == "__main__":
    # Sample dataset
    data = {
        'text': [
            "The service was terrible and the food was cold.",
            "I'm not satisfied with this product, it's a waste of money.",
            "This is the worst experience I've ever had!",
            "The delivery was late and the staff was rude.",
            "Absolutely wonderful experience, highly recommend!"
        ]
    }
    df = pd.DataFrame(data)
    
    # Initialize analyzer
    analyzer = NegativeSentimentAnalyzer()
    
    # Analyze dataset
    results = analyzer.analyze_dataset(df)
    
    # Display results
    print("Negative Sentiment Analysis Results:")
    print(results[['text', 'negative_terms', 'negative_score']].to_string(index=False))
